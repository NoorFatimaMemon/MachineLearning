{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Building Neural Networks from Scratch**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y = w1x1 + w2x2 + w3x3 + ... + wnxn + b\n",
    "\n",
    "Where b = bias.\n",
    "\n",
    "### **Creating a Basic Neuron with 3 Inputs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.5\n"
     ]
    }
   ],
   "source": [
    "inputs =  [1.0, 2.0, 3.0]    # Input values\n",
    "weights = [0.5, -1.5, 2.0]   # Weights associated with each input\n",
    "bias =    1.0                # Bias term\n",
    "\n",
    "# Calculate the output using the neuron equation\n",
    "output = inputs[0]*weights[0] + inputs[1]*weights[1] + inputs[2]*weights[2] + bias\n",
    "\n",
    "# Print the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Creating a Layer of Neurons with 4 Inputs and 3 Neurons**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.7000000000000002, -0.34999999999999964, 3.45]\n"
     ]
    }
   ],
   "source": [
    "inputs =   [1.5, 2.5, 3.5, 4.0]       # Input values\n",
    "\n",
    "weights1 = [0.1, 0.2, -0.3, 0.4]      # Weights for the first neuron\n",
    "weights2 = [0.4, -0.5, 0.6, -0.7]     # Weights for the second neuron\n",
    "weights3 = [-0.8, 0.9, -1.0, 1.1]     # Weights for the third neuron\n",
    "\n",
    "bias1 =    0.5                        # Bias for the first neuron\n",
    "bias2 =    1.0                        # Bias for the second neuron\n",
    "bias3 =    1.5                        # Bias for the third neuron\n",
    "\n",
    "# Calculate the output for each neuron\n",
    "output = [\n",
    "    inputs[0]*weights1[0] + inputs[1]*weights1[1] + inputs[2]*weights1[2] + inputs[3]*weights1[3] + bias1,\n",
    "    inputs[0]*weights2[0] + inputs[1]*weights2[1] + inputs[2]*weights2[2] + inputs[3]*weights2[3] + bias2,\n",
    "    inputs[0]*weights3[0] + inputs[1]*weights3[1] + inputs[2]*weights3[2] + inputs[3]*weights3[3] + bias3\n",
    "]\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Doing Dot Product with a Layer of Neurons and Multiple Inputs**\n",
    "\n",
    "y = w.x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.70000005 -0.35000002  3.45000005]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "inputs =  np.array([1.5, 2.5, 3.5, 4.0])  # Convert inputs to a NumPy array\n",
    "weights = np.array([\n",
    "    [0.1, 0.2, -0.3, 0.4],\n",
    "    [0.4, -0.5, 0.6, -0.7],\n",
    "    [-0.8, 0.9, -1.0, 1.1]\n",
    "])\n",
    "biases =  np.array([0.5, 1.0, 1.5])  # Convert biases to a NumPy array\n",
    "\n",
    "output = np.dot(weights, inputs) + biases\n",
    "print(output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Layers and Objects**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 01\n",
      " [[ 0.20417337  1.404173    0.29327127  0.4781426   0.19649717]\n",
      " [-0.08349796  0.70846415  0.00293357  0.44701523  0.3636054 ]\n",
      " [-0.50763243  0.5568842   0.07987796 -0.34889573  0.04553042]]\n",
      "Layer 02\n",
      " [[ 0.16812852 -0.11359761]\n",
      " [ 0.14100316 -0.01340469]\n",
      " [ 0.20124978 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.seed(0)\n",
    "\n",
    "X = np.array([[1.5, 2.5, 3.5, 4.0],\n",
    "              [2.0, 5.0, -1.0, 2.0],\n",
    "              [-1.5, 2.7, 3.3, -0.8]])\n",
    "\n",
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "\n",
    "layer1 = Layer_Dense(4,5)\n",
    "layer2 = Layer_Dense(5,2)\n",
    "\n",
    "layer1.forward(X)\n",
    "print(\"Layer 01\\n\", layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(\"Layer 02\\n\", layer2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **All in One with Hidden Layer Activation Function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nnfs in c:\\users\\noor\\appdata\\roaming\\python\\python39\\site-packages (0.5.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\noor\\appdata\\roaming\\python\\python39\\site-packages (from nnfs) (1.26.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.1.1 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install nnfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and Initialization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import nnfs\n",
    "from nnfs.datasets import spiral_data \n",
    "\n",
    "nnfs.init()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nnfs (Neural Networks from Scratch) is a custom library that provides tools and datasets for learning neural networks from scratch.\n",
    "\n",
    "from nnfs.datasets import spiral_data: Imports a specific function spiral_data from the datasets module within nnfs. This function generates a dataset commonly used to test neural network algorithms.\n",
    "\n",
    "nnfs.init(): Initializes nnfs. This typically sets up configurations or initializes necessary resources within the nnfs library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = spiral_data(100, 3)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above function call generates a synthetic dataset suitable for testing neural networks. \n",
    "\n",
    "It creates 100 data points (X) and their corresponding labels (y) with 3 classes. \n",
    "\n",
    "This dataset is often used to visualize and test classification algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Layer_Dense Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Layer_Dense:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.10 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Layer_Dense Class: This class represents a dense (fully connected) layer in a neural network.\n",
    "\n",
    "__init__(self, n_inputs, n_neurons): Constructor method that initializes the layer with random weights and biases.\n",
    "\n",
    "self.weights: Initialized with random values using np.random.randn(n_inputs, n_neurons), scaled by 0.10. These are the connection weights between input neurons and output neurons.\n",
    "\n",
    "self.biases: Initialized as zeros, shaped as (1, n_neurons). These biases are added to each neuron in the layer.\n",
    "\n",
    "forward(self, inputs): Method that performs the forward pass computation of the layer.\n",
    "\n",
    "inputs: Input data passed to the layer.\n",
    "\n",
    "self.output: This calculates the weighted sum of inputs plus biases, which forms the output of the layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Activation_ReLU Class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Activation_ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Activation_ReLU Class: Represents the ReLU (Rectified Linear Unit) activation function, which introduces non-linearity into the neural network.\n",
    "\n",
    "forward(self, inputs): Method that performs the ReLU activation function on the input data.\n",
    "\n",
    "self.output: This operation replaces any negative values in inputs with zero, effectively activating neurons only when their input is positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating and Using Layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 01\n",
      " [[ 0.00000000e+00  0.00000000e+00  0.00000000e+00  0.00000000e+00\n",
      "   0.00000000e+00]\n",
      " [-8.35815910e-04 -7.90404272e-04 -1.33452227e-03  4.65504505e-04\n",
      "   4.56846210e-05]\n",
      " [-2.39994470e-03  5.93469958e-05 -2.24808278e-03  2.03573116e-04\n",
      "   6.10024377e-04]\n",
      " ...\n",
      " [ 1.13291524e-01 -1.89262271e-01 -2.06855070e-02  8.11079666e-02\n",
      "  -6.71350807e-02]\n",
      " [ 1.34588361e-01 -1.43197834e-01  3.09493970e-02  5.66337556e-02\n",
      "  -6.29687458e-02]\n",
      " [ 1.07817926e-01 -2.00809643e-01 -3.37579325e-02  8.72561932e-02\n",
      "  -6.81458861e-02]]\n",
      "Layer 02\n",
      " [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 4.65504505e-04\n",
      "  4.56846210e-05]\n",
      " [0.00000000e+00 5.93469958e-05 0.00000000e+00 2.03573116e-04\n",
      "  6.10024377e-04]\n",
      " ...\n",
      " [1.13291524e-01 0.00000000e+00 0.00000000e+00 8.11079666e-02\n",
      "  0.00000000e+00]\n",
      " [1.34588361e-01 0.00000000e+00 3.09493970e-02 5.66337556e-02\n",
      "  0.00000000e+00]\n",
      " [1.07817926e-01 0.00000000e+00 0.00000000e+00 8.72561932e-02\n",
      "  0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "layer1 = Layer_Dense(2,5)\n",
    "activation1 = Activation_ReLU()\n",
    "\n",
    "layer1.forward(X)\n",
    "print(\"Layer 01\\n\", layer1.output)\n",
    "activation1.forward(layer1.output)\n",
    "print(\"Layer 02\\n\", activation1.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating Layers:**\n",
    "\n",
    "layer1 = Layer_Dense(2, 5): Creates a dense layer (Layer_Dense object) with 2 input neurons and 5 output neurons. layer1 initializes its weights and biases upon instantiation.\n",
    "\n",
    "activation1 = Activation_ReLU(): Creates an activation function (Activation_ReLU object).\n",
    "\n",
    "**Forward Pass:**\n",
    "layer1.forward(X): Performs the forward pass through layer1, applying its weights and biases to the dataset X (spiral_data). This computes layer1.output.\n",
    "\n",
    "**Applying Activation:** \n",
    "activation1.forward(layer1.output): Applies the ReLU activation function (Activation_ReLU) to the output of layer1. This computes activation1.output."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
